{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5094f04-46e1-439a-b071-19dd7025d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\" Clustering Algorithm \"\"\"\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\"\"\" \n",
    "Metrics for Number of Clusters\n",
    "Note \n",
    "Silhouette Score: The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. \n",
    "Davies Bouldin Score: The minimum score is zero, with lower values indicating better clustering.\n",
    "Calinski Harabasz Score: The score is a positive floating-point value, where higher values indicate better clustering.\n",
    "\"\"\"\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3f8dfa1-2437-4e3f-911f-157996e412b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" The clustering algorithm inside the dictionary datatype or a key-value pair data structure \"\"\"\n",
    "# random_state=42\n",
    "# CLUSTERS_DICT = {\n",
    "#     'kmeans': KMeans(random_state=random_state),\n",
    "#     'spectral': SpectralClustering(random_state=random_state),\n",
    "#     'hierarchical': AgglomerativeClustering(linkage='ward'),\n",
    "#     'agglomerative': AgglomerativeClustering(),\n",
    "#     'gaussian': GaussianMixture(random_state=random_state)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8967731c-2aff-4260-ac59-e6cef2febff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The clustering algorithm and metrics score inside the dictionary datatype or a key-value pair data structure \"\"\"\n",
    "#clusters\n",
    "CLUSTERS_DICT = {\n",
    "    'kmeans': KMeans,\n",
    "    'spectral': SpectralClustering,\n",
    "    'hierarchical': AgglomerativeClustering,\n",
    "    'agglomerative': AgglomerativeClustering,\n",
    "    'gaussian': GaussianMixture\n",
    "}\n",
    "\n",
    "# Metrics\n",
    "METRICS_DICT = {\n",
    "    'silhouette': silhouette_score,\n",
    "    'davies': davies_bouldin_score,\n",
    "    'calinski': calinski_harabasz_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "758326e5-6f0a-4eb1-b2b5-0e0bc378d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    def __init__(self, X, cluster_algo, random_state=42):\n",
    "        self.X = X\n",
    "        self.cluster_algo = cluster_algo # This is a reference of a clustering algorithm\n",
    "        self.metric_best_score = None\n",
    "        self.metric_scores = None\n",
    "        self.random_state=random_state\n",
    "\n",
    "    def find_n_cluster(self, metric, max_range=10):\n",
    "        self.metric = metric\n",
    "        self.n_cluster, self.metric_best_score = self._compute_n(self.cluster_algo, metric, max_range)\n",
    "        return self.n_cluster, self.metric_best_score\n",
    "\n",
    "    def _compute_n(self, cluster_algo, metric, max_range):\n",
    "        self.metric_scores = []\n",
    "        best_score = float('-inf') if metric != \"davies_bouldin\" else float('inf')\n",
    "        best_n_cluster = None\n",
    "        for k in range(2, max_range+1):\n",
    "            y_labels = self._create_cluster_instance_fit_predict(k)\n",
    "            score = silhouette_score(self.X, y_labels)\n",
    "            self.metric_scores.append(score)\n",
    "            if (metric == \"davies_bouldin\" and score < best_score) or (metric != \"davies_bouldin\" and score > best_score):\n",
    "                best_score = score\n",
    "                best_n_cluster = k      \n",
    "        # if metric==davies_bouldin_score:\n",
    "        #     return best_n_cluster, best_score\n",
    "        return best_n_cluster, best_score\n",
    "        \n",
    "    def _create_cluster_instance_fit_predict(self, k):\n",
    "        # KMeans\n",
    "        if self.cluster_algo == KMeans:\n",
    "            cluster = self.cluster_algo(n_clusters=k, random_state=self.random_state)\n",
    "            y_labels = cluster.fit_predict(self.X)\n",
    "    \n",
    "        # SpectralClustering\n",
    "        elif self/cluster_algo == SpectralClustering:\n",
    "            cluster = self.cluster_algo(n_clusters=k, random_state=self.random_state, affinity='nearest_neighbors')\n",
    "            y_labels = cluster.fit_predict(self.X)\n",
    "    \n",
    "        # Ward Hierarchical Clustering\n",
    "        # Agglomerative Clustering is a specific type of Hierarchical Clustering and use the linkage ward\n",
    "        elif self.cluster_algo == AgglomerativeClustering:\n",
    "            cluster = self.cluster_algo(n_clusters=k, random_state=self.random_state, linkage='ward')\n",
    "            y_labels = cluster.fit_predict(self.X)\n",
    "             \n",
    "        # # AgglomerativeClustering\n",
    "        # elif self.cluster_algo == AgglomerativeClustering:\n",
    "        #     cluster = self.cluster_algo(n_clusters=k)\n",
    "        #     y_labels = cluster.fit_predict(self.X)\n",
    "    \n",
    "        # GaussianMixture\n",
    "        elif self.cluster_algo == GaussianMixture:\n",
    "            cluster = self.cluster_algo(n_components=k, random_state=self.random_state)\n",
    "            cluster.fit(self.X)\n",
    "            y_labels = cluster.predict(self.X)\n",
    "    \n",
    "        # Handle unknown clustering algorithms\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported clustering algorithm: {cluster_algo}\")\n",
    "        return y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12bfd9ba-a87e-4810-8d24-b9b3fefcad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Voltage   Current  Power Factor  Frequency     Power\n",
      "0 -9.767521  9.480710      6.487488  -6.462790 -7.361530\n",
      "1 -8.560889  8.734477      6.489258  -4.808246 -6.589762\n",
      "2 -3.327672  7.511521      4.379144   0.847751 -7.028664\n",
      "3 -7.431058 -8.789943      6.635979   1.891384  3.126497\n",
      "4 -8.664148  8.975563      7.325451  -6.289177 -5.823476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "\n",
    "# Generate synthetic dataset\n",
    "n_samples = 500  # Number of data points\n",
    "n_features = 5   # Number of features\n",
    "n_clusters = 3   # Number of clusters\n",
    "\n",
    "X, y = make_blobs(n_samples=n_samples, n_features=n_features, centers=n_clusters, random_state=42)\n",
    "\n",
    "# Convert to a Pandas DataFrame for better visualization\n",
    "columns = ['Voltage', 'Current', 'Power Factor', 'Frequency', 'Power']\n",
    "df = pd.DataFrame(X, columns=columns)\n",
    "# df['Cluster'] = y  # Add cluster labels for reference (optional)\n",
    "\n",
    "print(df.head())  # Show the first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3637dbc-2d47-4f29-a907-d45a78692951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of best cluster: 3; Best Score: 0.7718348236319091;\n"
     ]
    }
   ],
   "source": [
    "kmeans = Clustering(X, CLUSTERS_DICT['kmeans'])\n",
    "n_cluster, best_score = kmeans.find_n_cluster(METRICS_DICT['silhouette'])\n",
    "print(f'Number of best cluster: {n_cluster}; Best Score: {best_score};')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7d528c4-0f18-4d2d-ae05-b3d37daeb3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.7422772235562364),\n",
       " np.float64(0.7718348236319091),\n",
       " np.float64(0.5790579710600725),\n",
       " np.float64(0.3904968274566857),\n",
       " np.float64(0.15392219409234362),\n",
       " np.float64(0.15249154274279758),\n",
       " np.float64(0.15143073182593317),\n",
       " np.float64(0.15517915916121405),\n",
       " np.float64(0.14892206257592097)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.metric_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6480bf8-92f8-4208-833e-c3213b2a7dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
